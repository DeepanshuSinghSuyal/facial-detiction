<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>Emotion Mirror ðŸŒ¸</title>

<script defer src="https://unpkg.com/face-api.js"></script>

<style>
  body {
    margin: 0;
    font-family: 'Poppins', sans-serif;
    background: linear-gradient(135deg, #ffd6e8, #fff0f6);
    display: flex;
    justify-content: center;
    align-items: center;
    height: 100vh;
  }

  .card {
    background: white;
    padding: 20px;
    border-radius: 24px;
    box-shadow: 0 20px 40px rgba(255, 120, 180, 0.25);
    text-align: center;
    width: 360px;
  }

  h1 {
    color: #ff6fae;
    margin-bottom: 10px;
  }

  video {
    border-radius: 18px;
    width: 100%;
  }

  .emotion {
    margin-top: 15px;
    font-size: 18px;
    color: #ff5fa2;
  }

  .bar {
    height: 16px;
    background: #ffe1ef;
    border-radius: 20px;
    overflow: hidden;
    margin-top: 10px;
  }

  .fill {
    height: 100%;
    width: 0%;
    background: linear-gradient(90deg, #ff8dc7, #ff5fa2);
    transition: width 0.3s ease;
  }

  .footer {
    font-size: 12px;
    color: #aaa;
    margin-top: 10px;
  }
</style>
</head>

<body>

<div class="card">
  <h1>Emotion Mirror ðŸ’•</h1>
  <video id="video" autoplay muted></video>

  <div class="emotion" id="emotionText">
    Detecting your vibe...
  </div>

  <div class="bar">
    <div class="fill" id="happinessBar"></div>
  </div>

  <div class="footer">Smile a little ðŸŒ·</div>
</div>

<script>
const video = document.getElementById("video");
const emotionText = document.getElementById("emotionText");
const happinessBar = document.getElementById("happinessBar");

async function startCamera() {
  const stream = await navigator.mediaDevices.getUserMedia({ video: true });
  video.srcObject = stream;
}

async function loadModels() {
  await faceapi.nets.tinyFaceDetector.loadFromUri('./models');
  await faceapi.nets.faceExpressionNet.loadFromUri('./models');
}

async function detectEmotion() {
  const detection = await faceapi
    .detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
    .withFaceExpressions();

  if (!detection) return;

  const expressions = detection.expressions;

  const happiness = Math.round(expressions.happy * 100);
  const sadness = Math.round(expressions.sad * 100);
  const anger = Math.round(expressions.angry * 100);

  happinessBar.style.width = happiness + "%";

  let mood = "Neutral ðŸŒ¸";
  if (happiness > 40) mood = "Happy ðŸ’–";
  else if (sadness > 30) mood = "Sad ðŸ¥º";
  else if (anger > 30) mood = "Angry ðŸ˜¤";

  emotionText.innerHTML = `
    Mood: <b>${mood}</b><br>
    Happiness: ${happiness}%
  `;
}

(async () => {
  await loadModels();
  await startCamera();

  video.addEventListener("play", () => {
    setInterval(detectEmotion, 500);
  });
})();
</script>

</body>
</html>
